{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as Func\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 128, 3)\n",
    "        self.conv2 = nn.Conv2d(128, 256, 4)\n",
    "        self.conv3 = nn.Conv2d(256, 512, 3)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(256 * 5 * 5, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 10)\n",
    "        self.dropout = nn.Dropout(p=0.5);\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "        #x = F.relu(self.conv3(x))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "netCNN = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(128, 256, kernel_size=(4, 4), stride=(1, 1))\n",
       "  (conv3): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=6400, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc4): Linear(in_features=128, out_features=10, bias=True)\n",
       "  (dropout): Dropout(p=0.5)\n",
       ")"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_rows = 28\n",
    "img_cols = 28\n",
    "# for convolutional neural network\n",
    "x_train = pd.read_csv('train.csv')\n",
    "x_test = pd.read_csv('test.csv')\n",
    "y_train = x_train['label'].values\n",
    "x_train = x_train.drop(['label'],1)\n",
    "\n",
    "x_train = x_train.values\n",
    "x_test = x_test.values\n",
    "x_train = x_train.reshape(np.shape(x_train)[0],1,img_rows,img_cols)\n",
    "x_test = x_test.reshape(np.shape(x_test)[0],1,img_rows,img_cols)\n",
    "\n",
    "x_train = x_train.astype('float32')/255\n",
    "x_test = x_test.astype('float32')/255\n",
    "\n",
    "train = torch.from_numpy(x_train)\n",
    "test = torch.from_numpy(x_test)\n",
    "train_label = torch.from_numpy(y_train)\n",
    "#test_label = torch.from_numpy(y_test)\n",
    "train_label = train_label.long()\n",
    "batchsize = 500\n",
    "num_iterations = int(train.size(0)/batchsize)\n",
    "\n",
    "# select device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(netCNN.parameters(), lr=0.001)\n",
    "netCNN.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "to_tensor() missing 1 required positional argument: 'pic'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-93-c143deb83d7b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mtrain_pil\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrotation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_pil\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mtrain_pil\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_pil\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mtrain_temp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: to_tensor() missing 1 required positional argument: 'pic'"
     ]
    }
   ],
   "source": [
    "rotation = transforms.RandomRotation(15)\n",
    "crop = transforms.CenterCrop(15)\n",
    "train_temp = torch.empty(np.shape(x_train)[0],1,img_rows,img_cols)\n",
    "for n_input, input_data in enumerate(train):\n",
    "    train_pil = transforms.ToPILImage(mode=None)(train[n_input])\n",
    "    train_pil = rotation(train_pil)\n",
    "    train_pil = crop(train_pil)\n",
    "    train_temp[n_input,:,:,:] = Func.to_tensor(train_pil)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(train_temp[100][-1])\n",
    "plt.subplot(2,2,2)\n",
    "plt.imshow(train[100][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    84] loss: 82.002\n",
      "[2,    84] loss: 21.158\n",
      "[3,    84] loss: 15.155\n",
      "[4,    84] loss: 12.824\n",
      "[5,    84] loss: 11.571\n",
      "[6,    84] loss: 10.417\n",
      "[7,    84] loss: 9.529\n",
      "[8,    84] loss: 8.833\n",
      "[9,    84] loss: 8.889\n",
      "[10,    84] loss: 8.217\n",
      "[11,    84] loss: 7.816\n",
      "[12,    84] loss: 7.378\n",
      "[13,    84] loss: 7.063\n",
      "[14,    84] loss: 6.717\n",
      "[15,    84] loss: 6.536\n",
      "[16,    84] loss: 6.202\n",
      "[17,    84] loss: 6.085\n",
      "[18,    84] loss: 5.950\n",
      "[19,    84] loss: 5.711\n",
      "[20,    84] loss: 5.543\n",
      "[21,    84] loss: 5.496\n",
      "[22,    84] loss: 5.628\n",
      "[23,    84] loss: 5.340\n",
      "[24,    84] loss: 5.310\n",
      "[25,    84] loss: 5.040\n",
      "[26,    84] loss: 4.953\n",
      "[27,    84] loss: 4.956\n",
      "[28,    84] loss: 4.656\n",
      "[29,    84] loss: 4.726\n",
      "[30,    84] loss: 4.516\n",
      "[31,    84] loss: 4.291\n",
      "[32,    84] loss: 4.530\n",
      "[33,    84] loss: 4.311\n",
      "[34,    84] loss: 4.375\n",
      "[35,    84] loss: 4.110\n",
      "[36,    84] loss: 4.053\n",
      "[37,    84] loss: 4.239\n",
      "[38,    84] loss: 4.115\n",
      "[39,    84] loss: 4.059\n",
      "[40,    84] loss: 3.894\n",
      "[41,    84] loss: 3.782\n",
      "[42,    84] loss: 3.861\n",
      "[43,    84] loss: 3.826\n",
      "[44,    84] loss: 4.183\n",
      "[45,    84] loss: 3.710\n",
      "[46,    84] loss: 3.587\n",
      "[47,    84] loss: 3.290\n",
      "[48,    84] loss: 3.512\n",
      "[49,    84] loss: 3.447\n",
      "[50,    84] loss: 3.637\n",
      "Finished Training\n",
      "0.9931190476190476\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "rotation = transforms.RandomRotation(10)\n",
    "\n",
    "train_temp = torch.empty(np.shape(x_train)[0],1,img_rows,img_cols)\n",
    "\n",
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "    for n_input, input_data in enumerate(train):\n",
    "        train_pil = transforms.ToPILImage(mode=None)(train[n_input])\n",
    "        train_temp[n_input,:,:,:] = Func.to_tensor(rotation(train_pil))\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i in range(num_iterations):\n",
    "        # get the inputs\n",
    "        # can put data augmentation here\n",
    "        inputs = train_temp[i*batchsize:(i+1)*batchsize]\n",
    "        labels = train_label[i*batchsize:(i+1)*batchsize]\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = netCNN(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "    print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss))\n",
    "    running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "prediction_all = torch.empty(train.size(0),1)\n",
    "for i in range(num_iterations):\n",
    "    test_input = train[i*batchsize:(i+1)*batchsize]\n",
    "    output = netCNN(test_input.to(device))\n",
    "    _, prediction = torch.max(output,1)\n",
    "    prediction_all[i*batchsize:(i+1)*batchsize,0] = prediction\n",
    "\n",
    "match = train_label.int().reshape(train.size(0),1) == prediction_all.cpu().int()\n",
    "fraction = int(match.sum())/int(prediction_all.shape[0])\n",
    "print(fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = int(test.size(0)/batchsize)\n",
    "prediction_all = torch.empty(test.size(0),1)\n",
    "for i in range(num_iterations):\n",
    "    test_input = test[i*batchsize:(i+1)*batchsize]\n",
    "    output = netCNN(test_input.to(device))\n",
    "    _, prediction = torch.max(output,1)\n",
    "    prediction_all[i*batchsize:(i+1)*batchsize,0] = prediction\n",
    "predicted_cpu = prediction_all.cpu()\n",
    "image_id = np.linspace(1,test.size(0),test.size(0))\n",
    "image_id.astype(int)\n",
    "predicted_final = np.array(predicted_cpu)\n",
    "predicted_final = predicted_final.astype(int)\n",
    "output_file = 'submission.csv'\n",
    "#print(predicted_final)\n",
    "\n",
    "with open(output_file, 'w') as f :\n",
    "    f.write('ImageId,Label\\n')\n",
    "    for i in range(len(predicted_final)) :\n",
    "        f.write(\"\".join([str(i+1),',',str(predicted_final[i][0]),'\\n']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetFC(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(NetFC, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.fc1 = nn.Linear(28*28, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 40)\n",
    "        self.fc4 = nn.Linear(40, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "netFC = NetFC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for fully connected neural network\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "img_rows = 28\n",
    "img_cols = 28\n",
    "x_train = x_train.reshape(x_train.shape[0], 1, img_rows*img_cols)\n",
    "x_test = x_test.reshape(x_test.shape[0], 1, img_rows*img_cols)\n",
    "x_train = x_train.astype('float32')/255\n",
    "x_test = x_test.astype('float32')/255\n",
    "train = torch.from_numpy(x_train)\n",
    "test = torch.from_numpy(x_test)\n",
    "train_label = torch.from_numpy(y_train)\n",
    "test_label = torch.from_numpy(y_test)\n",
    "train_label = train_label.long()\n",
    "batchsize = 100\n",
    "num_iterations = int(train.size(0)/batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NetFC(\n",
       "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=40, bias=True)\n",
       "  (fc4): Linear(in_features=40, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(netFC.parameters(), lr=0.001)\n",
    "netFC.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   600] loss: 283.888\n",
      "[2,   600] loss: 106.718\n",
      "[3,   600] loss: 72.281\n",
      "[4,   600] loss: 54.142\n",
      "[5,   600] loss: 42.713\n",
      "[6,   600] loss: 33.680\n",
      "[7,   600] loss: 26.459\n",
      "[8,   600] loss: 21.393\n",
      "[9,   600] loss: 19.270\n",
      "[10,   600] loss: 16.055\n",
      "Finished Training\n",
      "Fraction Correct: 97.44\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i in range(num_iterations):\n",
    "        # get the inputs\n",
    "        inputs = train[i*batchsize:(i+1)*batchsize]\n",
    "        labels = train_label[i*batchsize:(i+1)*batchsize]\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = netFC(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "    print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss))\n",
    "    running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "testimage = test.reshape(test.shape[0],28*28,1)\n",
    "output = netFC(testimage.to(device))\n",
    "_, predicted = torch.max(output,1)\n",
    "match = test_label.int().to(device) == predicted.int()\n",
    "fraction = int(match.sum())/int(predicted.shape[0])\n",
    "print('Fraction Correct: %.2f' % (fraction*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
